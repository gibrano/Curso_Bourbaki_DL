{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba73d261-d193-4e45-a83d-7c374810386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "385fbbdf-599e-4d72-aeef-0e923f376584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1.0 - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5dcd7fd-c5fd-4ca1-aa63-b67ff073ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tiny deterministic network: 2 -> 2 -> 2 -> 2 -> 1 (3 hidden layers) ---\n",
    "# Weights (Wl: shape [n_l, n_{l-1}]), biases (bl: shape [n_l])\n",
    "W1 = [[0.3, -0.2],\n",
    "      [0.1,  0.4]]\n",
    "b1 = [0.0, 0.1]\n",
    "\n",
    "W2 = [[-0.5, 0.2],\n",
    "      [ 0.3, 0.7]]\n",
    "b2 = [0.2, -0.3]\n",
    "\n",
    "W3 = [[ 0.6, -0.1],\n",
    "      [-0.4,  0.2]]\n",
    "b3 = [-0.2, 0.05]\n",
    "\n",
    "W4 = [[0.8, -0.6]]  # output layer: 1 x 2\n",
    "b4 = [0.15]\n",
    "\n",
    "# Single data point (supervised)\n",
    "x = [0.7, -1.2]\n",
    "y_true = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd78c7c-867d-4ad2-b00a-5ebfcea292d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Forward pass (store z and a per layer) ---\n",
    "def matvec(W, v):\n",
    "    return [sum(W[i][j]*v[j] for j in range(len(v))) for i in range(len(W))]\n",
    "\n",
    "def vecadd(a, b):\n",
    "    return [a[i] + b[i] for i in range(len(a))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023d360c-bc8b-4bcd-bbdd-504eadcc1564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055878068519147776"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# layer 1\n",
    "z1 = vecadd(matvec(W1, x), b1)\n",
    "a1 = [sigmoid(z) for z in z1]\n",
    "\n",
    "# layer 2\n",
    "z2 = vecadd(matvec(W2, a1), b2)\n",
    "a2 = [sigmoid(z) for z in z2]\n",
    "\n",
    "# layer 3\n",
    "z3 = vecadd(matvec(W3, a2), b3)\n",
    "a3 = [sigmoid(z) for z in z3]\n",
    "\n",
    "# output layer\n",
    "z4 = vecadd(matvec(W4, a3), b4)  # 1-dim list\n",
    "y_hat = sigmoid(z4[0])\n",
    "\n",
    "# Loss: 0.5 * (y - y_hat)^2\n",
    "L = 0.5 * (y_true - y_hat)**2\n",
    "\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66555351-a446-4ff7-830e-4925569d4fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_counter = defaultdict(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c1d9315-dfa7-4f3e-9dcf-13173ad98a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map layer index to activations and pre-activations\n",
    "# Layers: 1..4 (4 is output layer)\n",
    "Z = {1: z1, 2: z2, 3: z3, 4: z4}\n",
    "A = {0: x, 1: a1, 2: a2, 3: a3, 4: [y_hat]}  # A[0] is input; A[4] is post-activation output\n",
    "W = {1: W1, 2: W2, 3: W3, 4: W4}\n",
    "b = {1: b1, 2: b2, 3: b3, 4: b4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eeabef9-a3dc-435f-825e-6dbefec10c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful sizes\n",
    "sizes = {0: len(x), 1: len(a1), 2: len(a2), 3: len(a3), 4: 1}\n",
    "\n",
    "# Derivative of loss wrt pre-activation z_l[i], computed naively with recursion and NO caching.\n",
    "def dL_dz_naive(l, i):\n",
    "    call_counter[(l, i)] += 1\n",
    "    if l == 4:\n",
    "        # dL/dz4 = (y_hat - y_true) * sigmoid'(z4)\n",
    "        return (y_hat - y_true) * d_sigmoid(Z[4][0])\n",
    "    else:\n",
    "        # dL/da_l[i] = sum_m dL/dz_{l+1}[m] * d z_{l+1}[m] / d a_l[i]\n",
    "        # z_{l+1}[m] = sum_k W_{l+1}[m,k] * a_l[k] + b_{l+1}[m]\n",
    "        # => derivative wrt a_l[i] is W_{l+1}[m, i]\n",
    "        s = 0.0\n",
    "        for m in range(sizes[l+1]):\n",
    "            # Critically, this recursively recomputes dL/dz_{l+1}[m] again and again for different i.\n",
    "            s += dL_dz_naive(l+1, m) * W[l+1][m][i]\n",
    "        # Chain by activation derivative at layer l\n",
    "        return s * d_sigmoid(Z[l][i])\n",
    "\n",
    "# Gradients wrt weights and biases using the naive dL_dz\n",
    "def grad_W_naive(l, i, j):\n",
    "    # dL/dW_l[i,j] = dL/dz_l[i] * d z_l[i] / d W_l[i,j] = dL/dz_l[i] * a_{l-1}[j]\n",
    "    return dL_dz_naive(l, i) * A[l-1][j]\n",
    "\n",
    "def grad_b_naive(l, i):\n",
    "    # dL/db_l[i] = dL/dz_l[i] * d z_l[i] / d b_l[i] = dL/dz_l[i]\n",
    "    return dL_dz_naive(l, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30d8c4ea-6611-4664-941e-a4e4293a2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all gradients (this will trigger tons of redundant recursive calls)\n",
    "grads_W = {l: [[0.0]*len(W[l][0]) for _ in range(len(W[l]))] for l in [1,2,3,4]}\n",
    "grads_b = {l: [0.0]*len(b[l]) for l in [1,2,3,4]}\n",
    "\n",
    "for l in [1,2,3,4]:\n",
    "    for i in range(len(W[l])):\n",
    "        for j in range(len(W[l][0])):\n",
    "            grads_W[l][i][j] = grad_W_naive(l, i, j)\n",
    "    for i in range(len(b[l])):\n",
    "        grads_b[l][i] = grad_b_naive(l, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f416862-f1f7-40f4-88f3-bcbd5a7e44e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [[0.0003582243755061708, -0.0006140989294391499],\n",
       "  [-4.473004029712163e-06, 7.668006908077993e-06]],\n",
       " 2: [[-0.0022556775919990012, -0.001562969397063531],\n",
       "  [0.000621642245487877, 0.0004307387762620629]],\n",
       " 3: [[-0.008124538649331792, -0.008943799091209098],\n",
       "  [0.006093830245667664, 0.006708318560053563]],\n",
       " 4: [[-0.041936867458953586, -0.04026553028316163]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e80e88b-f2db-4e0a-a37e-376c9a2404ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [0.0005117491078659583, -6.390005756731661e-06],\n",
       " 2: [-0.0036939611256399767, 0.0010180188414483206],\n",
       " 3: [-0.016418980336164235, 0.012315096683522982],\n",
       " 4: [-0.0821318445040607]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b904b5f2-3e30-4c72-a52e-cca9de7dbd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass:\n",
      "  x    = [0.7, -1.2]\n",
      "  z1   = [0.44999999999999996, -0.30999999999999994]\n",
      "  a1   = [0.610639233949222, 0.42311473886795364]\n",
      "  z2   = [-0.020696669201020257, 0.17937208739233418]\n",
      "  a2   = [0.49482601738895976, 0.5447231745268372]\n",
      "  z3   = [0.04242329298069214, -0.038985772050216486]\n",
      "  a3   = [0.5106042328914234, 0.49025479126029914]\n",
      "  z4   = [0.2643305115569593]\n",
      "  y_hat= 0.565701\n",
      "  Loss = 0.05587807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "print(\"Forward pass:\")\n",
    "print(f\"  x    = {x}\")\n",
    "print(f\"  z1   = {z1}\\n  a1   = {a1}\")\n",
    "print(f\"  z2   = {z2}\\n  a2   = {a2}\")\n",
    "print(f\"  z3   = {z3}\\n  a3   = {a3}\")\n",
    "print(f\"  z4   = {z4}\\n  y_hat= {y_hat:.6f}\")\n",
    "print(f\"  Loss = {L:.8f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cf62864-5c6a-4cdf-ba8c-fa090d661e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive (no-backprop) gradients:\n",
      "W1 grads:\n",
      "   ['0.00035822', '-0.00061410']\n",
      "   ['-0.00000447', '0.00000767']\n",
      "b1 grads:\n",
      "   ['0.00051175', '-0.00000639']\n",
      "\n",
      "W2 grads:\n",
      "   ['-0.00225568', '-0.00156297']\n",
      "   ['0.00062164', '0.00043074']\n",
      "b2 grads:\n",
      "   ['-0.00369396', '0.00101802']\n",
      "\n",
      "W3 grads:\n",
      "   ['-0.00812454', '-0.00894380']\n",
      "   ['0.00609383', '0.00670832']\n",
      "b3 grads:\n",
      "   ['-0.01641898', '0.01231510']\n",
      "\n",
      "W4 grads:\n",
      "   ['-0.04193687', '-0.04026553']\n",
      "b4 grads:\n",
      "   ['-0.08213184']\n",
      "\n",
      "Total dL/dz naive calls (showing blow-up due to no reuse): 111\n",
      "  calls dL/dz for layer 1 neuron 0: 3\n",
      "  calls dL/dz for layer 1 neuron 1: 3\n",
      "  calls dL/dz for layer 2 neuron 0: 9\n",
      "  calls dL/dz for layer 2 neuron 1: 9\n",
      "  calls dL/dz for layer 3 neuron 0: 21\n",
      "  calls dL/dz for layer 3 neuron 1: 21\n",
      "  calls dL/dz for layer 4 neuron 0: 45\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive (no-backprop) gradients:\")\n",
    "for l in [1,2,3,4]:\n",
    "    print(f\"W{l} grads:\")\n",
    "    for row in grads_W[l]:\n",
    "        print(\"  \", [f\"{v:.8f}\" for v in row])\n",
    "    print(f\"b{l} grads:\")\n",
    "    print(\"  \", [f\"{v:.8f}\" for v in grads_b[l]])\n",
    "    print()\n",
    "\n",
    "# Show how many times each dL/dz_l[i] was recomputed\n",
    "total_calls = sum(call_counter.values())\n",
    "print(f\"Total dL/dz naive calls (showing blow-up due to no reuse): {total_calls}\")\n",
    "for key in sorted(call_counter.keys()):\n",
    "    print(f\"  calls dL/dz for layer {key[0]} neuron {key[1]}: {call_counter[key]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8c2d6f-c645-4633-b6f8-24b8c29cc569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
